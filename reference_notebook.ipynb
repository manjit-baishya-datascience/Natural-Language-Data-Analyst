{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Installing libraries**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:29.126291Z",
     "iopub.status.busy": "2026-02-20T17:54:29.125619Z",
     "iopub.status.idle": "2026-02-20T17:54:38.872489Z",
     "shell.execute_reply": "2026-02-20T17:54:38.871468Z",
     "shell.execute_reply.started": "2026-02-20T17:54:29.126252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manjit\\AppData\\Local\\Temp\\ipykernel_6580\\2043909488.py:3: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **API Configuration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieveing API KEY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:38.873969Z",
     "iopub.status.busy": "2026-02-20T17:54:38.873457Z",
     "iopub.status.idle": "2026-02-20T17:54:39.004285Z",
     "shell.execute_reply": "2026-02-20T17:54:39.003086Z",
     "shell.execute_reply.started": "2026-02-20T17:54:38.873941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not set in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checking for availabel models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:39.007441Z",
     "iopub.status.busy": "2026-02-20T17:54:39.006975Z",
     "iopub.status.idle": "2026-02-20T17:54:39.203306Z",
     "shell.execute_reply": "2026-02-20T17:54:39.201696Z",
     "shell.execute_reply.started": "2026-02-20T17:54:39.007404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n"
     ]
    }
   ],
   "source": [
    "# Setting API KEY\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Getting available models list\n",
    "models = list(genai.list_models())\n",
    "\n",
    "# Printing first 5 models\n",
    "for m in models[:5]:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Selecting model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:39.205100Z",
     "iopub.status.busy": "2026-02-20T17:54:39.204645Z",
     "iopub.status.idle": "2026-02-20T17:54:39.210247Z",
     "shell.execute_reply": "2026-02-20T17:54:39.209244Z",
     "shell.execute_reply.started": "2026-02-20T17:54:39.205061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading and Processing Dataset**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:39.211859Z",
     "iopub.status.busy": "2026-02-20T17:54:39.211493Z",
     "iopub.status.idle": "2026-02-20T17:54:39.272983Z",
     "shell.execute_reply": "2026-02-20T17:54:39.271961Z",
     "shell.execute_reply.started": "2026-02-20T17:54:39.211813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/titanic_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Schema Extraction Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:39.274692Z",
     "iopub.status.busy": "2026-02-20T17:54:39.274352Z",
     "iopub.status.idle": "2026-02-20T17:54:39.281937Z",
     "shell.execute_reply": "2026-02-20T17:54:39.280821Z",
     "shell.execute_reply.started": "2026-02-20T17:54:39.274655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_schema(df):\n",
    "    schema = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        schema.append({\n",
    "            \"column_name\": col,\n",
    "            \"dtype\": str(df[col].dtype),\n",
    "            \"non_null_count\": int(df[col].notnull().sum()),\n",
    "            \"unique_values\": int(df[col].nunique())\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"num_rows\": len(df),\n",
    "        \"num_columns\": len(df.columns),\n",
    "        \"columns\": schema,\n",
    "        \"sample_rows\": df.head(2).to_dict(orient=\"records\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracting schema and inspecting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:39.283369Z",
     "iopub.status.busy": "2026-02-20T17:54:39.282987Z",
     "iopub.status.idle": "2026-02-20T17:54:39.315720Z",
     "shell.execute_reply": "2026-02-20T17:54:39.314511Z",
     "shell.execute_reply.started": "2026-02-20T17:54:39.283330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"num_rows\": 418,\n",
      " \"num_columns\": 12,\n",
      " \"columns\": [\n",
      "  {\n",
      "   \"column_name\": \"PassengerId\",\n",
      "   \"dtype\": \"int64\",\n",
      "   \"non_null_count\": 418,\n",
      "   \"unique_values\": 418\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Survived\",\n",
      "   \"dtype\": \"int64\",\n",
      "   \"non_null_count\": 418,\n",
      "   \"unique_values\": 2\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Pclass\",\n",
      "   \"dtype\": \"int64\",\n",
      "   \"non_null_count\": 418,\n",
      "   \"unique_values\": 3\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Name\",\n",
      "   \"dtype\": \"str\",\n",
      "   \"non_null_count\": 418,\n",
      "   \"unique_values\": 418\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Sex\",\n",
      "   \"dtype\": \"str\",\n",
      "   \"non_null_count\": 418,\n",
      "   \"unique_values\": 2\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Age\",\n",
      "   \"dtype\": \"float64\",\n",
      "   \"non_null_count\": 332,\n",
      "   \"unique_values\": 79\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"SibSp\",\n",
      "   \"dtype\": \"int64\",\n",
      "   \"non_null_count\": 418,\n",
      "   \"unique_values\": 7\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Parch\",\n",
      "   \"dtype\": \"int64\",\n",
      "   \"non_null_count\": 418,\n",
      "   \"unique_values\": 8\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Ticket\",\n",
      "   \"dtype\": \"str\",\n",
      "   \"non_null_count\": 418,\n",
      "   \"unique_values\": 363\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Fare\",\n",
      "   \"dtype\": \"float64\",\n",
      "   \"non_null_count\": 417,\n",
      "   \"unique_values\": 169\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Cabin\",\n",
      "   \"dtype\": \"str\",\n",
      "   \"non_null_count\": 91,\n",
      "   \"unique_values\": 76\n",
      "  },\n",
      "  {\n",
      "   \"column_name\": \"Embarked\",\n",
      "   \"dtype\": \"str\",\n",
      "   \"non_null_count\": 418,\n",
      "   \"unique_values\": 3\n",
      "  }\n",
      " ],\n",
      " \"sample_rows\": [\n",
      "  {\n",
      "   \"PassengerId\": 892,\n",
      "   \"Survived\": 0,\n",
      "   \"Pclass\": 3,\n",
      "   \"Name\": \"Kelly, Mr. James\",\n",
      "   \"Sex\": \"male\",\n",
      "   \"Age\": 34.5,\n",
      "   \"SibSp\": 0,\n",
      "   \"Parch\": 0,\n",
      "   \"Ticket\": \"330911\",\n",
      "   \"Fare\": 7.8292,\n",
      "   \"Cabin\": NaN,\n",
      "   \"Embarked\": \"Q\"\n",
      "  },\n",
      "  {\n",
      "   \"PassengerId\": 893,\n",
      "   \"Survived\": 1,\n",
      "   \"Pclass\": 3,\n",
      "   \"Name\": \"Wilkes, Mrs. James (Ellen Needs)\",\n",
      "   \"Sex\": \"female\",\n",
      "   \"Age\": 47.0,\n",
      "   \"SibSp\": 1,\n",
      "   \"Parch\": 0,\n",
      "   \"Ticket\": \"363272\",\n",
      "   \"Fare\": 7.0,\n",
      "   \"Cabin\": NaN,\n",
      "   \"Embarked\": \"S\"\n",
      "  }\n",
      " ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataset_info = extract_schema(df)\n",
    "\n",
    "print(json.dumps(dataset_info, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prompt Construction**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Defining prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:39.318104Z",
     "iopub.status.busy": "2026-02-20T17:54:39.317210Z",
     "iopub.status.idle": "2026-02-20T17:54:39.327408Z",
     "shell.execute_reply": "2026-02-20T17:54:39.326359Z",
     "shell.execute_reply.started": "2026-02-20T17:54:39.318064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_prompt(dataset_info, question):\n",
    "    return f\"\"\"\n",
    "You are a senior data analyst.\n",
    "\n",
    "You are given:\n",
    "1. Dataset metadata\n",
    "2. A user question\n",
    "\n",
    "Your task:\n",
    "- Generate SAFE pandas code using ONLY dataframe `df`\n",
    "- Do NOT import anything\n",
    "- Do NOT assign variables\n",
    "- Return a JSON object with keys:\n",
    "    - analysis_type\n",
    "    - pandas_code\n",
    "    - reasoning\n",
    "\n",
    "Rules:\n",
    "- pandas_code must be a SINGLE expression\n",
    "- No loops\n",
    "- No comprehensions\n",
    "- No file access\n",
    "- No __ usage\n",
    "- Only pandas operations on df\n",
    "\n",
    "Dataset Metadata:\n",
    "{json.dumps(dataset_info, indent=2)}\n",
    "\n",
    "User Question:\n",
    "{question}\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Calling Gemini and Parsing Output**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLM Call Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:39.330713Z",
     "iopub.status.busy": "2026-02-20T17:54:39.330412Z",
     "iopub.status.idle": "2026-02-20T17:54:39.344831Z",
     "shell.execute_reply": "2026-02-20T17:54:39.343601Z",
     "shell.execute_reply.started": "2026-02-20T17:54:39.330673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def query_gemini(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Structured Parsing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:39.346319Z",
     "iopub.status.busy": "2026-02-20T17:54:39.345957Z",
     "iopub.status.idle": "2026-02-20T17:54:39.362746Z",
     "shell.execute_reply": "2026-02-20T17:54:39.361721Z",
     "shell.execute_reply.started": "2026-02-20T17:54:39.346292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json_block(text):\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start != -1 and end != -1:\n",
    "        return text[start:end+1]\n",
    "    return text\n",
    "    \n",
    "def parse_llm_output(raw_output):\n",
    "    try:\n",
    "        json_str = extract_json_block(raw_output)\n",
    "        return json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        print(\"JSON Parsing Failed:\", e)\n",
    "        print(\"Raw Output:\\n\", raw_output)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:39.364421Z",
     "iopub.status.busy": "2026-02-20T17:54:39.363860Z",
     "iopub.status.idle": "2026-02-20T17:54:40.949968Z",
     "shell.execute_reply": "2026-02-20T17:54:40.949143Z",
     "shell.execute_reply.started": "2026-02-20T17:54:39.364392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "--------------------------------------------------\n",
      "```json\n",
      "{\n",
      "  \"analysis_type\": \"summary\",\n",
      "  \"pandas_code\": \"len(df)\",\n",
      "  \"reasoning\": \"The user is asking for the total number of passengers onboard, which directly corresponds to the total number of rows in the DataFrame. The `len()` function applied to a DataFrame returns its number of rows.\"\n",
      "}\n",
      "```\n",
      "Parsed LLM Output\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'analysis_type': 'summary',\n",
       " 'pandas_code': 'len(df)',\n",
       " 'reasoning': 'The user is asking for the total number of passengers onboard, which directly corresponds to the total number of rows in the DataFrame. The `len()` function applied to a DataFrame returns its number of rows.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What as the total number of passengers onboard?\"\n",
    "\n",
    "prompt = build_prompt(dataset_info, question)\n",
    "raw_output = query_gemini(prompt)\n",
    "\n",
    "print(\"Raw Output\")\n",
    "print(\"-\"*50)\n",
    "print(raw_output)\n",
    "\n",
    "print(\"Parsed LLM Output\")\n",
    "print(\"-\"*50)\n",
    "parsed = parse_llm_output(raw_output)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building safe execution layer**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Basic Static Safety Filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:40.951563Z",
     "iopub.status.busy": "2026-02-20T17:54:40.951174Z",
     "iopub.status.idle": "2026-02-20T17:54:40.957595Z",
     "shell.execute_reply": "2026-02-20T17:54:40.956621Z",
     "shell.execute_reply.started": "2026-02-20T17:54:40.951538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "FORBIDDEN_KEYWORDS = [\n",
    "    \"import\",\n",
    "    \"__\",\n",
    "    \"exec\",\n",
    "    \"eval\",\n",
    "    \"open\",\n",
    "    \"write\",\n",
    "    \"read\",\n",
    "    \"os\",\n",
    "    \"sys\",\n",
    "    \"subprocess\",\n",
    "    \"pickle\",\n",
    "    \"to_csv\",\n",
    "    \"to_excel\"\n",
    "]\n",
    "\n",
    "def basic_safety_check(code):\n",
    "    for word in FORBIDDEN_KEYWORDS:\n",
    "        if word in code:\n",
    "            raise ValueError(f\"Unsafe keyword detected: {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AST Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:40.959005Z",
     "iopub.status.busy": "2026-02-20T17:54:40.958666Z",
     "iopub.status.idle": "2026-02-20T17:54:40.977544Z",
     "shell.execute_reply": "2026-02-20T17:54:40.976240Z",
     "shell.execute_reply.started": "2026-02-20T17:54:40.958967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ast_validate(code):\n",
    "    try:\n",
    "        tree = ast.parse(code, mode=\"eval\")  # only expressions allowed\n",
    "    except:\n",
    "        raise ValueError(\"Code is not a valid single expression.\")\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "\n",
    "        if isinstance(node, (ast.Import, ast.ImportFrom)):\n",
    "            raise ValueError(\"Imports not allowed.\")\n",
    "\n",
    "        if isinstance(node, ast.Call):\n",
    "            if isinstance(node.func, ast.Name):\n",
    "                if node.func.id not in [\"len\", \"sum\", \"min\", \"max\"]:\n",
    "                    # Allow pandas method calls via df only\n",
    "                    pass\n",
    "\n",
    "        if isinstance(node, ast.Name):\n",
    "            if node.id not in [\"df\", \"len\", \"sum\", \"min\", \"max\"]:\n",
    "                raise ValueError(f\"Unauthorized variable: {node.id}\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Automatic Repair Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:41.019282Z",
     "iopub.status.busy": "2026-02-20T17:54:41.018894Z",
     "iopub.status.idle": "2026-02-20T17:54:41.034309Z",
     "shell.execute_reply": "2026-02-20T17:54:41.033372Z",
     "shell.execute_reply.started": "2026-02-20T17:54:41.019241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def execute_with_repair(parsed_output, df, dataset_info, question, max_retries=2):\n",
    "    \n",
    "    current_output = parsed_output\n",
    "    \n",
    "    for attempt in range(max_retries + 1):\n",
    "        \n",
    "        code = current_output[\"pandas_code\"]\n",
    "        \n",
    "        try:\n",
    "            result = safe_execute(code, df)\n",
    "            return result, current_output\n",
    "        \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"Attempt {attempt+1} failed.\")\n",
    "            print(\"Error:\", str(e))\n",
    "            \n",
    "            if attempt == max_retries:\n",
    "                raise RuntimeError(\"Max retries exceeded.\")\n",
    "            \n",
    "            # Build repair prompt\n",
    "            repair_prompt = f\"\"\"\n",
    "The following pandas expression failed:\n",
    "\n",
    "Expression:\n",
    "{code}\n",
    "\n",
    "Error:\n",
    "{str(e)}\n",
    "\n",
    "Dataset Metadata:\n",
    "{json.dumps(dataset_info, indent=2)}\n",
    "\n",
    "User Question:\n",
    "{question}\n",
    "\n",
    "Return corrected JSON with:\n",
    "- analysis_type\n",
    "- pandas_code\n",
    "- reasoning\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "\"\"\"\n",
    "            \n",
    "            raw = query_gemini(repair_prompt)\n",
    "            repaired = parse_llm_output(raw)\n",
    "            \n",
    "            if repaired is None:\n",
    "                raise RuntimeError(\"Repair output not parseable.\")\n",
    "            \n",
    "            current_output = repaired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Adding Result Normalizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:42.612384Z",
     "iopub.status.busy": "2026-02-20T17:54:42.611647Z",
     "iopub.status.idle": "2026-02-20T17:54:42.617956Z",
     "shell.execute_reply": "2026-02-20T17:54:42.617271Z",
     "shell.execute_reply.started": "2026-02-20T17:54:42.612351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_result(result):\n",
    "    \n",
    "    # Convert numpy scalars to native Python\n",
    "    if isinstance(result, (np.integer, np.int64)):\n",
    "        return int(result)\n",
    "    \n",
    "    if isinstance(result, (np.floating, np.float64)):\n",
    "        return float(result)\n",
    "    \n",
    "    # Convert pandas Series\n",
    "    if isinstance(result, pd.Series):\n",
    "        return result.to_dict()\n",
    "    \n",
    "    # Convert pandas DataFrame\n",
    "    if isinstance(result, pd.DataFrame):\n",
    "        return result.to_dict(orient=\"records\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Safe Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:42.619951Z",
     "iopub.status.busy": "2026-02-20T17:54:42.619294Z",
     "iopub.status.idle": "2026-02-20T17:54:42.663080Z",
     "shell.execute_reply": "2026-02-20T17:54:42.662211Z",
     "shell.execute_reply.started": "2026-02-20T17:54:42.619922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def safe_execute(code, df):\n",
    "    basic_safety_check(code)\n",
    "    ast_validate(code)\n",
    "\n",
    "    allowed_builtins = {\n",
    "        \"len\": len,\n",
    "        \"sum\": sum,\n",
    "        \"min\": min,\n",
    "        \"max\": max\n",
    "    }\n",
    "\n",
    "    safe_globals = {\"__builtins__\": allowed_builtins}\n",
    "    safe_locals = {\"df\": df}\n",
    "\n",
    "    try:\n",
    "        result = eval(code, safe_globals, safe_locals)\n",
    "        return normalize_result(result)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Execution error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Building Exaplaination Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:44.044806Z",
     "iopub.status.busy": "2026-02-20T17:54:44.044398Z",
     "iopub.status.idle": "2026-02-20T17:54:44.049755Z",
     "shell.execute_reply": "2026-02-20T17:54:44.048734Z",
     "shell.execute_reply.started": "2026-02-20T17:54:44.044780Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_explanation_prompt(question, pandas_code, result):\n",
    "    \n",
    "    return f\"\"\"\n",
    "You are a data analyst.\n",
    "\n",
    "The user asked:\n",
    "{question}\n",
    "\n",
    "The system executed this pandas expression:\n",
    "{pandas_code}\n",
    "\n",
    "The computed result is:\n",
    "{result}\n",
    "\n",
    "Explain the result clearly in simple English.\n",
    "\n",
    "Be concise.\n",
    "Do not mention internal system details.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Explaination function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:44.051432Z",
     "iopub.status.busy": "2026-02-20T17:54:44.050965Z",
     "iopub.status.idle": "2026-02-20T17:54:44.067770Z",
     "shell.execute_reply": "2026-02-20T17:54:44.066811Z",
     "shell.execute_reply.started": "2026-02-20T17:54:44.051396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_explanation(question, pandas_code, result):\n",
    "    \n",
    "    prompt = build_explanation_prompt(question, pandas_code, result)\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T17:54:44.069320Z",
     "iopub.status.busy": "2026-02-20T17:54:44.068891Z",
     "iopub.status.idle": "2026-02-20T17:54:52.980371Z",
     "shell.execute_reply": "2026-02-20T17:54:52.979545Z",
     "shell.execute_reply.started": "2026-02-20T17:54:44.069293Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Among the people who survived, 152 were females. No males were found.\n"
     ]
    }
   ],
   "source": [
    "question = \"Out of the people who survived, how many were males and how many were females?\"\n",
    "\n",
    "prompt = build_prompt(dataset_info, question)\n",
    "raw_output = query_gemini(prompt)\n",
    "parsed = parse_llm_output(raw_output)\n",
    "parsed\n",
    "\n",
    "result, final_output = execute_with_repair(parsed, df, dataset_info, question)\n",
    "\n",
    "explanation = generate_explanation(\n",
    "    question,\n",
    "    final_output[\"pandas_code\"],\n",
    "    result\n",
    ")\n",
    "\n",
    "print(\"\\nAnswer:\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2926173,
     "datasetId": 826163,
     "sourceId": 2879186,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
